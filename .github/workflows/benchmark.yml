name: Semantica Performance Suite

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

jobs:
  performance-test:
    name: Benchmark Runner (Ubuntu/Python 3.12)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: 'pip'

      - name: Install Dependencies
        env:

          BENCHMARK_REAL_LIBS: "1"
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r benchmarks/requirements.txt
          python -m spacy download en_core_web_sm
          pip install rdflib neo4j faiss-cpu torch pyarrow pdfplumber python-pptx openpyxl lxml python-docx beautifulsoup4 chardet langdetect

      - name: Execute Benchmarks (Real Mode)
        env:
          BENCHMARK_REAL_LIBS: "1"
        run: |
          python benchmarks/benchmarks_runner.py
          # Optional: Compare to baseline (requires previous run artifact)
          # pytest-benchmark --storage file://benchmarks/results --benchmark-compare

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: benchmark-report-${{ github.run_id }}
          path: benchmarks/results
          retention-days: 30
