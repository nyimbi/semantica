<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantica - Use Case Examples</title>
    <style>
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            line-height: 1.6; 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px; 
            background-color: #f5f5f5;
        }
        h1 { 
            color: #2c3e50; 
            border-bottom: 4px solid #3498db; 
            padding-bottom: 15px;
            text-align: center;
            font-size: 2.5em;
        }
        h2 { 
            color: #34495e; 
            margin-top: 30px; 
            border-bottom: 3px solid #3498db; 
            padding-bottom: 10px;
            font-size: 1.8em;
        }
        h3 { 
            color: #555; 
            margin-top: 20px;
            font-size: 1.3em;
        }
        pre { 
            background-color: #2c3e50; 
            color: #ecf0f1;
            padding: 20px; 
            border-radius: 8px; 
            overflow-x: auto; 
            font-size: 13px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
        }
        .usecase { 
            background: white;
            padding: 30px; 
            margin: 30px 0; 
            border-left: 5px solid #3498db;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .benefit { 
            background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
            border-left: 5px solid #28a745;
            padding: 20px; 
            margin: 20px 0; 
            border-radius: 6px;
        }
        .benefit h4 {
            color: #155724;
            margin-top: 0;
        }
        code { 
            background-color: #f4f4f4; 
            padding: 2px 6px; 
            border-radius: 3px; 
            font-family: 'Courier New', monospace;
            color: #e74c3c;
        }
        .icon {
            font-size: 2em;
            margin-right: 10px;
        }
        .stats-box {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        .stat-item {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
        }
        .stat-number {
            font-size: 2em;
            font-weight: bold;
        }
        .persona-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        .persona-card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-top: 4px solid #3498db;
        }
        .persona-card h4 {
            color: #2c3e50;
            margin-top: 0;
        }
        .workflow {
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .workflow-step {
            background: #e8f4f8;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 10px 0;
            border-radius: 4px;
        }
        ul {
            padding-left: 20px;
        }
        li {
            margin: 8px 0;
        }
    </style>
</head>
<body>
    <h1>üéØ Semantica Framework - Use Case Examples</h1>
    
    <h2>Use Case 1: Enterprise Knowledge Graph Construction</h2>
    <div class="usecase">
        <h3><span class="icon">üè¢</span>Scenario</h3>
        <p>A large enterprise needs to build a unified knowledge graph from diverse internal sources: company documents (PDFs, Word files), emails, databases, and web content. The knowledge graph should enable semantic search, relationship discovery, and support AI-powered assistants.</p>
        
        <h3>üìã Implementation</h3>
        <pre><code>from semantica import Semantica
from semantica.ingest import FileIngestor, EmailIngestor, DBIngestor

# Initialize framework
core = Semantica(
    graph_db="neo4j",
    merge_entities=True,
    resolve_conflicts=True
)

# Ingest from multiple sources
file_ingestor = FileIngestor(recursive=True)
sources = []
sources.extend(file_ingestor.ingest("/company/documents/"))
sources.extend(file_ingestor.ingest("/company/reports/"))

email_ingestor = EmailIngestor()
sources.extend(email_ingestor.ingest("/company/emails/"))

db_ingestor = DBIngestor(connection_string="postgresql://...")
sources.extend(db_ingestor.ingest("SELECT * FROM knowledge_base"))

# Build unified knowledge graph
kg = core.build_knowledge_graph(
    sources=sources,
    merge_entities=True,
    resolve_conflicts=True,
    generate_embeddings=True
)

# Export to Neo4j for production use
kg.to_neo4j("bolt://neo4j-server:7687", "neo4j", "password")

print(f"‚úÖ Built knowledge graph: {kg.node_count} nodes, {kg.edge_count} edges")</code></pre>
        
        <div class="workflow">
            <h4>Workflow Steps:</h4>
            <div class="workflow-step">1. Ingest documents from multiple sources (files, emails, databases)</div>
            <div class="workflow-step">2. Parse and extract content from all formats</div>
            <div class="workflow-step">3. Extract entities and relationships automatically</div>
            <div class="workflow-step">4. Resolve entity duplicates and conflicts</div>
            <div class="workflow-step">5. Build unified knowledge graph</div>
            <div class="workflow-step">6. Export to Neo4j for production queries</div>
        </div>
        
        <h3>‚úÖ Expected Outcomes</h3>
        <div class="benefit">
            <h4>Key Benefits:</h4>
            <ul>
                <li><strong>Unified Knowledge:</strong> Single source of truth from all enterprise data</li>
                <li><strong>Semantic Search:</strong> Find information by meaning, not just keywords</li>
                <li><strong>Relationship Discovery:</strong> Automatically discover connections between entities</li>
                <li><strong>AI Assistant Support:</strong> Structured knowledge for RAG and agent systems</li>
            </ul>
        </div>
        
        <div class="stats-box">
            <div class="stat-item">
                <div>Faster Discovery</div>
            </div>
            <div class="stat-item">
                <div>Auto Cross-Reference</div>
            </div>
            <div class="stat-item">
                <div>Less Manual Work</div>
            </div>
        </div>
    </div>
    
    <h2>Use Case 2: GraphRAG for Research Assistant</h2>
    <div class="usecase">
        <h3><span class="icon">üî¨</span>Scenario</h3>
        <p>A research organization wants to build an AI assistant that can answer complex questions about scientific literature by combining vector search with knowledge graph traversal for better context understanding.</p>
        
        <h3>üìã Implementation</h3>
        <pre><code>from semantica import Semantica
from semantica.qa_rag import GraphRAGEngine
from semantica.vector_store import VectorStore, PineconeAdapter

# Build knowledge base from research papers
core = Semantica(
    vector_store="pinecone",
    graph_db="neo4j",
    embedding_model="text-embedding-3-large"
)

kb = core.build_knowledge_base(
    sources=["research_papers/"],
    generate_embeddings=True,
    build_graph=True
)

# Initialize GraphRAG
vector_store = VectorStore(adapter=PineconeAdapter(
    api_key="your-key",
    index_name="research-kb"
))

graphrag = GraphRAGEngine(
    vector_store=kb.vector_store,
    knowledge_graph=kb.graph,
    embedding_model="text-embedding-3-large",
    rerank=True
)

# Query with hybrid retrieval
query = "What are the main findings about climate change impacts on agriculture?"
response = graphrag.query(
    query=query,
    top_k=5,
    expand_graph=True,
    max_hops=2
)

print(f"Answer: {response.answer}")
print(f"Confidence: {response.confidence:.2f}")
print(f"Sources: {len(response.sources)}")
for source in response.sources:
    print(f"  - {source.title} (relevance: {source.score:.2f})")</code></pre>
        
        <div class="workflow">
            <h4>GraphRAG Process:</h4>
            <div class="workflow-step">1. Vector search finds top-K similar chunks</div>
            <div class="workflow-step">2. Extract entities from retrieved chunks</div>
            <div class="workflow-step">3. Expand graph from seed entities (2-3 hops)</div>
            <div class="workflow-step">4. Combine vector and graph results</div>
            <div class="workflow-step">5. Rerank and build structured context</div>
            <div class="workflow-step">6. Generate answer with citations</div>
        </div>
        
        <h3>‚úÖ Expected Outcomes</h3>
        <div class="benefit">
            <h4>Performance Improvements:</h4>
            <ul>
                <li><strong>Significant Accuracy Improvement:</strong> Over vector-only RAG systems</li>
                <li><strong>Better Context:</strong> Graph traversal provides related concepts</li>
                <li><strong>Citation Support:</strong> Traceable sources for all answers</li>
                <li><strong>Complex Queries:</strong> Answer multi-hop questions requiring reasoning</li>
            </ul>
        </div>
        
        <div class="stats-box">
            <div class="stat-item">
                <div>High Accuracy</div>
            </div>
            <div class="stat-item">
                <div>Significant Improvement</div>
            </div>
            <div class="stat-item">
                <div>Low Latency</div>
            </div>
        </div>
    </div>
    
    <h2>Use Case 3: Automatic Ontology Generation for Domain Modeling</h2>
    <div class="usecase">
        <h3><span class="icon">üè•</span>Scenario</h3>
        <p>A healthcare organization needs to create a formal ontology for their domain knowledge to enable semantic interoperability and reasoning. Manual ontology engineering is time-consuming and error-prone.</p>
        
        <h3>üìã Implementation</h3>
        <pre><code>from semantica.ontology import (
    OntologyGenerator,
    OntologyValidator,
    RequirementsSpec
)

# Define competency questions
requirements = RequirementsSpec()
requirements.add_competency_question(
    "What medical conditions exist?",
    category="entity_identification"
)
requirements.add_competency_question(
    "What are the relationships between conditions and treatments?",
    category="relationship_modeling"
)

# Generate ontology from documents
generator = OntologyGenerator(
    llm_provider="openai",
    model="gpt-4",
    validation_mode="hybrid"
)

ontology = generator.generate_from_documents(
    sources=["medical_documents/", "clinical_notes/", "research_papers/"],
    requirements=requirements,
    quality_threshold=0.9,
    namespace="https://example.org/medical#",
    prefix="med"
)

# Validate with symbolic reasoner
validator = OntologyValidator(reasoner="hermit")
validation_report = validator.validate(ontology)

if validation_report.is_consistent:
    print(f"‚úÖ Ontology generated: {len(ontology.classes)} classes")
    print(f"‚úÖ Validation score: {ontology.validation_score:.2f}")
    
    # Export to OWL
    from semantica.ontology import OWLGenerator
    owl_generator = OWLGenerator()
    owl_generator.generate(ontology, "medical_ontology.ttl", format="turtle")
    print("‚úÖ Saved to medical_ontology.ttl")
else:
    print("‚ùå Validation issues found")
    for issue in validation_report.issues:
        print(f"  - {issue.message}")</code></pre>
        
        <div class="workflow">
            <h4>Multi-Stage Ontology Generation:</h4>
            <div class="workflow-step">1. Semantic Network Parsing - Extract domain concepts</div>
            <div class="workflow-step">2. YAML-to-Definition - Transform to class definitions</div>
            <div class="workflow-step">3. Definition-to-Types - Map to OWL types</div>
            <div class="workflow-step">4. Hierarchy Generation - Build taxonomic structures</div>
            <div class="workflow-step">5. TTL Generation - Generate OWL/Turtle syntax</div>
            <div class="workflow-step">6. Symbolic Validation - HermiT/Pellet reasoning</div>
        </div>
        
        <h3>‚úÖ Expected Outcomes</h3>
        <div class="benefit">
            <h4>Key Advantages:</h4>
            <ul>
                <li><strong>Automatic Generation:</strong> W3C-compliant OWL ontology from unstructured content</li>
                <li><strong>High Quality:</strong> Excellent validation scores with symbolic reasoning</li>
                <li><strong>Time Savings:</strong> Significantly faster than manual ontology engineering</li>
                <li><strong>Interoperability:</strong> Standard OWL format for integration</li>
            </ul>
        </div>
        
        <div class="stats-box">
            <div class="stat-item">
                <div>High Quality</div>
            </div>
            <div class="stat-item">
                <div>Much Faster</div>
            </div>
            <div class="stat-item">
                <div>W3C Compliant</div>
            </div>
        </div>
    </div>
    
    <h2>Use Case 4: AI Agent with Persistent Memory</h2>
    <div class="usecase">
        <h3><span class="icon">ü§ñ</span>Scenario</h3>
        <p>An AI agent needs persistent memory across conversations, understanding user preferences, and maintaining context about past interactions. The agent should be able to reason about relationships and make decisions based on structured knowledge.</p>
        
        <h3>üìã Implementation</h3>
        <pre><code>from semantica.context import (
    ContextGraphBuilder,
    AgentMemory,
    ContextRetriever
)
from semantica.vector_store import VectorStore, PineconeAdapter

# Build context graph from conversations
context_builder = ContextGraphBuilder(
    extract_entities=True,
    extract_relationships=True,
    link_external_entities=True
)

context_graph = context_builder.build_from_conversations(
    conversations=["conv_history.json"],
    link_entities=True,
    extract_intents=True
)

# Initialize agent memory
vector_store = VectorStore(adapter=PineconeAdapter(
    api_key="your-key",
    index_name="agent-memory"
))

memory = AgentMemory(
    vector_store=vector_store,
    knowledge_graph=context_graph,
    retention_policy="30_days",
    max_memory_size=10000
)

# Store context
memory.store(
    content="User prefers technical documentation over tutorials",
    metadata={"user_id": "user_123", "category": "preferences"},
    entities=["User", "Documentation", "Tutorials"],
    relationships=[("prefers", "User", "Documentation")]
)

# Retrieve relevant context
context_retriever = ContextRetriever(
    memory_store=memory,
    use_graph_expansion=True,
    max_expansion_hops=2
)

relevant_context = context_retriever.retrieve(
    query="What are the user's learning preferences?",
    max_results=5,
    min_relevance_score=0.6
)

# Use context for agent decision-making
for ctx in relevant_context:
    print(f"- {ctx.content} (score: {ctx.score:.2f})")
    if ctx.related_entities:
        print(f"  Related: {[e.name for e in ctx.related_entities]}")</code></pre>
        
        <h3>‚úÖ Expected Outcomes</h3>
        <div class="benefit">
            <h4>Agent Capabilities:</h4>
            <ul>
                <li><strong>Persistent Memory:</strong> Context maintained across conversations</li>
                <li><strong>Graph-Enhanced Retrieval:</strong> Related concepts discovered through graph traversal</li>
                <li><strong>Personalization:</strong> Agent adapts to user preferences</li>
                <li><strong>Context-Aware Responses:</strong> Better understanding of user intent</li>
            </ul>
        </div>
    </div>
    
    <h2>Use Case 5: Multi-Source Data Integration with Conflict Resolution</h2>
    <div class="usecase">
        <h3><span class="icon">üíº</span>Scenario</h3>
        <p>A financial institution needs to integrate data from multiple sources (internal databases, external APIs, news feeds) into a unified knowledge graph, handling conflicts and duplicates automatically.</p>
        
        <h3>üìã Implementation</h3>
        <pre><code>from semantica import Semantica
from semantica.conflicts import ConflictDetector, ConflictResolver
from semantica.deduplication import DuplicateDetector, EntityMerger

# Initialize with conflict resolution
core = Semantica(
    graph_db="neo4j",
    merge_entities=True,
    resolve_conflicts=True
)

# Build knowledge graph from multiple sources
kg = core.build_knowledge_graph(
    sources=[
        "internal_database/",
        "external_apis/",
        "news_feeds/"
    ],
    merge_entities=True,
    resolve_conflicts=True
)

# Detect and resolve conflicts
conflict_detector = ConflictDetector()
conflicts = conflict_detector.detect_conflicts(
    entities=kg.entities,
    properties=["revenue", "employee_count", "market_cap"]
)

print(f"‚ö†Ô∏è  Found {len(conflicts)} conflicts")

# Resolve conflicts automatically
conflict_resolver = ConflictResolver()
for conflict in conflicts:
    resolution = conflict_resolver.resolve(
        conflict=conflict,
        strategy="highest_confidence"
    )
    print(f"‚úÖ Resolved: {conflict.entity.name}.{conflict.property} = {resolution.chosen_value}")

# Detect and merge duplicates
duplicate_detector = DuplicateDetector()
duplicates = duplicate_detector.find_duplicates(
    entities=kg.entities,
    similarity_threshold=0.8
)

entity_merger = EntityMerger()
merged = entity_merger.merge_duplicates(
    duplicates=duplicates,
    strategy="highest_confidence"
)

print(f"‚úÖ Merged {len(duplicates)} duplicate groups into {len(merged)} canonical entities")

# Quality assessment
from semantica.kg_qa import QualityAssessor
assessor = QualityAssessor()
report = assessor.assess(kg)

print(f"‚úÖ Quality Score: {report.overall_score}/100")
print(f"   Completeness: {report.completeness_score}/100")
print(f"   Consistency: {report.consistency_score}/100")</code></pre>
        
        <h3>‚úÖ Expected Outcomes</h3>
        <div class="benefit">
            <h4>Integration Benefits:</h4>
            <ul>
                <li><strong>Unified Knowledge Graph:</strong> Single source of truth from multiple sources</li>
                <li><strong>Automatic Conflict Resolution:</strong> Handles conflicting information intelligently</li>
                <li><strong>Duplicate Elimination:</strong> Merges duplicate entities automatically</li>
                <li><strong>Quality Assurance:</strong> Comprehensive quality metrics and reporting</li>
            </ul>
        </div>
    </div>
    
    <h2>üë• Target User Personas</h2>
    
    <div class="persona-grid">
        <div class="persona-card">
            <h4>ü§ñ AI/ML Engineer</h4>
            <p><strong>Needs:</strong> Build RAG systems, AI agents with structured knowledge</p>
            <p><strong>Use Case:</strong> GraphRAG, context engineering for agents</p>
            <p><strong>Value:</strong> Significant accuracy improvement, easier agent development</p>
        </div>
        
        <div class="persona-card">
            <h4>üìä Data Engineer</h4>
            <p><strong>Needs:</strong> Integrate semantic layers into data pipelines</p>
            <p><strong>Use Case:</strong> Multi-source knowledge graph construction</p>
            <p><strong>Value:</strong> Automated data integration, conflict resolution</p>
        </div>
        
        <div class="persona-card">
            <h4>üìö Knowledge Manager</h4>
            <p><strong>Needs:</strong> Build enterprise knowledge graphs from documents</p>
            <p><strong>Use Case:</strong> Enterprise knowledge graph construction</p>
            <p><strong>Value:</strong> Much faster information discovery, automatic relationship discovery</p>
        </div>
        
        <div class="persona-card">
            <h4>üî¨ Researcher</h4>
            <p><strong>Needs:</strong> Extract and structure knowledge from literature</p>
            <p><strong>Use Case:</strong> Research assistant, ontology generation</p>
            <p><strong>Value:</strong> Automatic ontology generation, semantic search</p>
        </div>
    </div>
    
    <hr>
    <p style="text-align: center; color: #666; margin-top: 40px;">
        <em>Document Version: 2.0 | Semantica Framework Use Cases | Last Updated: 2025</em>
    </p>
</body>
</html>
