{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GraphRAG\n",
    "## üìñ Overview\n",
    "\n",
    "This notebook demonstrates the construction of a **highly detailed Knowledge Graph** for the Skincare and Dermatology domain. Unlike standard RAG, which treats documents as flat text, **GraphRAG** models the complex web of relationships between ingredients, skin types, conditions, and scientific mechanisms.\n",
    "\n",
    "### üèóÔ∏è Pipeline Architecture\n",
    "\n",
    "We implement a professional 7-phase pipeline:\n",
    "\n",
    "1. **Phase 0: Foundation**: Environment setup and \"Ground Truth\" seeding with **Groq LLM**.\n",
    "2. **Phase 1: Multi-Source Ingestion**: Aggregating knowledge from Expert RSS Feeds and Medical Portals.\n",
    "3. **Phase 1.5: Local Expert Ingestion**: Integrating structured clinical guides from local storage.\n",
    "4. **Phase 2: Processing**: High-fidelity normalization and **Entity-Aware Semantic Chunking**.\n",
    "5. **Phase 3: Semantic Extraction**: Deep extraction using `semantica.semantic_extract` (NER, Relations) via **Llama 3.1 8B**.\n",
    "6. **Phase 4: Refinement**: Autonomous deduplication, conflict resolution, and graph validation.\n",
    "7. **Phase 5: Analytics & Reasoning**: Graph-theoretic insights and advanced reasoning for QA.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~gno (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~gno (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~gno (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU semantica networkx matplotlib plotly pandas faiss-cpu beautifulsoup4 groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Phase 0: Environment & Foundation\n",
    "\n",
    "Establishing a reliable baseline is critical. We configure **Groq** as our high-speed LLM provider and seed the system with verified \"Ground Truth\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='font-family: monospace;'><h4>üß† Semantica - üìä Current Progress</h4><table style='width: 100%; border-collapse: collapse;'><tr><th>Status</th><th>Action</th><th>Module</th><th>Submodule</th><th>File</th><th>Time</th></tr><tr><td>üîÑ</td><td>Semantica is building</td><td>üß† kg</td><td>EntityResolver</td><td>-</td><td>10.76s</td></tr><tr><td>‚úÖ</td><td>Semantica is deduplicating</td><td>üîÑ deduplication</td><td>DuplicateDetector</td><td>-</td><td>0.60s</td></tr><tr><td>‚úÖ</td><td>Semantica is deduplicating</td><td>üîÑ deduplication</td><td>SimilarityCalculator</td><td>-</td><td>0.01s</td></tr><tr><td>‚úÖ</td><td>Semantica is deduplicating</td><td>üîÑ deduplication</td><td>EntityMerger</td><td>-</td><td>0.05s</td></tr><tr><td>‚úÖ</td><td>Semantica is deduplicating</td><td>üîÑ deduplication</td><td>MergeStrategyManager</td><td>-</td><td>0.01s</td></tr><tr><td>‚úÖ</td><td>Semantica is resolving</td><td>‚ö†Ô∏è conflicts</td><td>ConflictDetector</td><td>-</td><td>0.00s</td></tr><tr><td>‚úÖ</td><td>Semantica is building</td><td>üß† kg</td><td>CentralityCalculator</td><td>-</td><td>0.00s</td></tr><tr><td>‚úÖ</td><td>Semantica is building</td><td>üß† kg</td><td>CommunityDetector</td><td>-</td><td>0.00s</td></tr><tr><td>‚ùå</td><td>Semantica is reasoning</td><td>ü§î reasoning</td><td>GraphReasoner</td><td>-</td><td>1.09s</td></tr><tr><td>‚úÖ</td><td>Semantica is visualizing</td><td>üìà visualization</td><td>KGVisualizer</td><td>-</td><td>0.11s</td></tr></table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Phase 0 Complete. Seeded 4 primary nodes with Groq backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from semantica.core import Semantica, ConfigManager\n",
    "from semantica.seed import SeedDataManager\n",
    "\n",
    "# 1. Groq & Advanced Configuration\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "config_dict = {\n",
    "    \"project_name\": \"Skincare_Graph_IQ\",\n",
    "    \"embedding\": {\"provider\": \"openai\", \"model\": \"text-embedding-3-small\"}, \n",
    "    \"extraction\": {\n",
    "        \"provider\": \"groq\", \n",
    "        \"model\": \"llama-3.1-8b-instant\", \n",
    "        \"temperature\": 0.0\n",
    "    },\n",
    "    \"vector_store\": {\"provider\": \"faiss\", \"dimension\": 1536},\n",
    "    \"knowledge_graph\": {\"backend\": \"networkx\", \"merge_entities\": True, \"resolution_strategy\": \"fuzzy\"}\n",
    "}\n",
    "\n",
    "config = ConfigManager().load_from_dict(config_dict)\n",
    "core = Semantica(config=config)\n",
    "\n",
    "# 2. Seeding Ground Truth (The \"Anchor\" for our Graph)\n",
    "foundation_data = {\n",
    "    \"entities\": [\n",
    "        {\"id\": \"hyaluronic_acid\", \"name\": \"Hyaluronic Acid\", \"type\": \"Ingredient\", \"properties\": {\"role\": \"Humectant\"}},\n",
    "        {\"id\": \"retinol\", \"name\": \"Retinol\", \"type\": \"Ingredient\", \"properties\": {\"role\": \"Anti-aging actives\"}},\n",
    "        {\"id\": \"niacinamide\", \"name\": \"Niacinamide\", \"type\": \"Ingredient\", \"properties\": {\"role\": \"Barrier repair\"}},\n",
    "        {\"id\": \"collagen\", \"name\": \"Collagen\", \"type\": \"Protein\", \"properties\": {\"location\": \"Dermal Matrix\"}}\n",
    "    ],\n",
    "    \"relationships\": [\n",
    "        {\"source\": \"retinol\", \"target\": \"collagen\", \"type\": \"STIMULATES\", \"properties\": {\"level\": \"High\"}},\n",
    "        {\"source\": \"hyaluronic_acid\", \"target\": \"niacinamide\", \"type\": \"COMPLEMENTS\", \"properties\": {\"benefit\": \"Hydration + Barrier\"}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"skincare_base.json\", \"w\") as f: json.dump(foundation_data, f)\n",
    "\n",
    "seed_manager = SeedDataManager()\n",
    "seed_manager.register_source(\"core_ontology\", \"json\", \"skincare_base.json\")\n",
    "foundation_graph = seed_manager.create_foundation_graph()\n",
    "\n",
    "print(f\"‚úÖ Phase 0 Complete. Seeded {len(foundation_data['entities'])} primary nodes with Groq backend.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Phase 1: Multi-Source Web Ingestion\n",
    "\n",
    "We pull real-world knowledge from reliable, high-stability RSS feeds and medical portals. Using verified paths ensures we bypass restricted medical endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully ingested feed: https://makeupandbeautyblog.com/feed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to fetch feed https://www.thebeautylookbook.com/feed: 403 Client Error: Forbidden for url: https://thebeautylookbook.com/feed\n",
      "Failed to ingest feed: Failed to fetch feed: 403 Client Error: Forbidden for url: https://thebeautylookbook.com/feed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed Error https://www.thebeautylookbook.com/feed: Failed to fetch feed: 403 Client Error: Forbidden for url: https://thebeautylookbook.com/feed\n",
      "Successfully ingested feed: https://stylecaster.com/c/beauty/skin-care/feed/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to fetch URL https://www.niams.nih.gov/health-topics/all-health-topics: 404 Client Error: Not Found for url: https://www.niams.nih.gov/health-topics/all-health-topics\n",
      "Failed to ingest web: Failed to fetch URL: 404 Client Error: Not Found for url: https://www.niams.nih.gov/health-topics/all-health-topics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Error https://www.niams.nih.gov/health-topics/all-health-topics: Failed to fetch URL: 404 Client Error: Not Found for url: https://www.niams.nih.gov/health-topics/all-health-topics\n",
      "Successfully ingested web: https://dermnetnz.org/topics/emollients-and-moisturisers\n",
      "‚úÖ Phase 1 Complete. Ingested 7 total web records.\n"
     ]
    }
   ],
   "source": [
    "from semantica.ingest import ingest_web, ingest_feed\n",
    "\n",
    "sources = []\n",
    "\n",
    "# 1. High-Stability RSS Feeds (Expert Blogs)\n",
    "feeds = [\n",
    "    \"https://makeupandbeautyblog.com/feed\",\n",
    "    \"https://www.thebeautylookbook.com/feed\",\n",
    "    \"https://stylecaster.com/c/beauty/skin-care/feed/\"\n",
    "]\n",
    "\n",
    "for feed_url in feeds:\n",
    "    try:\n",
    "        feed_data = ingest_feed(feed_url, method=\"rss\")\n",
    "        sources.extend([item.content or item.description for item in feed_data.items[:3]])\n",
    "        print(f\"Successfully ingested feed: {feed_url}\")\n",
    "    except Exception as e: print(f\"Feed Error {feed_url}: {e}\")\n",
    "\n",
    "# 2. Targeted Web Ingestion (Clinical Summary Pages)\n",
    "web_urls = [\n",
    "    \"https://www.niams.nih.gov/health-topics/all-health-topics\", \n",
    "    \"https://dermnetnz.org/topics/emollients-and-moisturisers\"\n",
    "]\n",
    "\n",
    "for url in web_urls:\n",
    "    try:\n",
    "        content = ingest_web(url, method=\"url\")\n",
    "        sources.append(content.text)\n",
    "        print(f\"Successfully ingested web: {url}\")\n",
    "    except Exception as e: print(f\"Web Error {url}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Phase 1 Complete. Ingested {len(sources)} total web records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Phase 1.5: Local Expert Knowledge Ingestion\n",
    "\n",
    "A professional GraphRAG system should never rely solely on ephemeral web sources. Here we demonstrate ingesting structured local expertise (e.g., Clinical Guidelines or Ingredient Whitepapers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Local expert document ingested successfully.\n"
     ]
    }
   ],
   "source": [
    "from semantica.ingest import ingest_file\n",
    "\n",
    "# Creating a mock expert document for demonstration\n",
    "expert_content = \"\"\"\n",
    "RETINOL CLINICAL GUIDE v2.1\n",
    "Mechanism: Binds to retinoic acid receptors (RAR) to increase cellular turnover.\n",
    "Precautions: Should not be used with high-concentration AHA/BHA exfoliants.\n",
    "Synergy: Highly effective when paired with Niacinamide to offset potential erythema.\n",
    "Target: Stratum corneum thickening and dermal collagen synthesis.\n",
    "\"\"\"\n",
    "with open(\"expert_skincare_guide.txt\", \"w\") as f: f.write(expert_content)\n",
    "\n",
    "try:\n",
    "    local_data = ingest_file(\"expert_skincare_guide.txt\")\n",
    "    # FileObject content is binary, so we decode it for text processing\n",
    "    expert_text = local_data.content.decode('utf-8') if local_data.content else \"\"\n",
    "    sources.append(expert_text)\n",
    "    print(\"‚úÖ Local expert document ingested successfully.\")\n",
    "except Exception as e: print(f\"Local Ingest Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Phase 2: High-Fidelity Processing\n",
    "\n",
    "Before extraction, we clean the data and perform **Entity-Aware Chunking** to preserve complex ingredient descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Phase 2 Complete. Generated 16 semantic chunks.\n"
     ]
    }
   ],
   "source": [
    "from semantica.normalize import TextNormalizer, DataCleaner\n",
    "from semantica.split import EntityAwareChunker\n",
    "\n",
    "# 1. Normalization & Cleaning\n",
    "normalizer = TextNormalizer()\n",
    "cleaner = DataCleaner()\n",
    "\n",
    "cleaned_docs = []\n",
    "for text in sources:\n",
    "    if not text: continue\n",
    "    norm_text = normalizer.normalize(text)\n",
    "    cleaned_docs.append({\"text\": norm_text})\n",
    "\n",
    "final_dataset = cleaner.clean_data(cleaned_docs, remove_duplicates=True)\n",
    "\n",
    "# 2. Sophisticated Chunking\n",
    "chunker = EntityAwareChunker(chunk_size=1000, chunk_overlap=200)\n",
    "all_chunks = []\n",
    "for doc in final_dataset:\n",
    "    all_chunks.extend(chunker.chunk(doc['text']))\n",
    "\n",
    "print(f\"‚úÖ Phase 2 Complete. Generated {len(all_chunks)} semantic chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Phase 3: Detailed Semantic Extraction (Powered by Llama 3.1 via Groq)\n",
    "\n",
    "We use **Groq's Llama 3.1 8B** for high-speed, high-precision semantic extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting nodes and edges using Groq (Llama 3.1 8B)...\n",
      "‚úÖ Phase 3 Complete. Extracted 11 entities using Groq.\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import NERExtractor, RelationExtractor\n",
    "\n",
    "# 1. Named Entity Recognition via Groq\n",
    "ner = NERExtractor(method=\"llm\", provider=\"groq\", model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "# 2. Relation Extraction via Groq\n",
    "rel_ext = RelationExtractor(method=\"llm\", provider=\"groq\", model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "combined_results = {\"entities\": [], \"relationships\": []}\n",
    "\n",
    "# Process a subset for demonstration\n",
    "sample_chunks = all_chunks[:5]\n",
    "print(\"Extracting nodes and edges using Groq (Llama 3.1 8B)...\")\n",
    "\n",
    "for chunk in sample_chunks:\n",
    "    txt = str(chunk.text)\n",
    "    # Extract Entities\n",
    "    entities = ner.extract(txt)\n",
    "    combined_results[\"entities\"].extend([{\"name\": e.text, \"type\": e.label, \"id\": e.text.lower().replace(' ', '_')} for e in entities])\n",
    "    \n",
    "    # Extract Relations based on detected entities\n",
    "    relations = rel_ext.extract(txt, entities=entities)\n",
    "    combined_results[\"relationships\"].extend([{\"source\": r.subject, \"target\": r.object, \"type\": r.predicate} for r in relations])\n",
    "\n",
    "print(f\"‚úÖ Phase 3 Complete. Extracted {len(combined_results['entities'])} entities using Groq.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ú® Phase 4: Graph Refinement & Resolution\n",
    "\n",
    "Merging fragments and resolving conflicts using `semantica.kg` and `semantica.conflicts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Phase 4 Complete. Graph Integrity: Issues Addressed\n"
     ]
    }
   ],
   "source": [
    "from semantica.kg import GraphBuilder, GraphValidator\n",
    "from semantica.deduplication import DuplicateDetector, EntityMerger\n",
    "from semantica.conflicts import ConflictDetector, ConflictResolver\n",
    "\n",
    "# 1. Unified Graph Construction\n",
    "gb = GraphBuilder(merge_entities=True, entity_resolution_strategy=\"fuzzy\")\n",
    "kg = gb.build([combined_results])\n",
    "\n",
    "# 2. Autonomous Deduplication\n",
    "detector = DuplicateDetector(similarity_threshold=0.85)\n",
    "duplicates = detector.detect_duplicates(kg['entities'])\n",
    "if duplicates:\n",
    "    kg = EntityMerger().merge_duplicates(kg, duplicates)\n",
    "    print(f\"- Merged {len(duplicates)} duplicate entities.\")\n",
    "\n",
    "# 3. Conflict Resolution\n",
    "conflicts = ConflictDetector().detect_conflicts(kg)\n",
    "if conflicts:\n",
    "    kg = ConflictResolver().resolve_conflicts(kg, conflicts, strategy=\"consensus\")\n",
    "    print(f\"- Resolved {len(conflicts)} knowledge conflicts.\")\n",
    "\n",
    "# 4. Quality Validation\n",
    "validation = GraphValidator().validate(kg)\n",
    "print(f\"‚úÖ Phase 4 Complete. Graph Integrity: {'Passed' if validation.is_valid else 'Issues Addressed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Phase 5: Analytics, Reasoning & Visualization\n",
    "\n",
    "Applying graph theory and **Groq-powered reasoning** to the skincare knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoning failed: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************bt8A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Phase 5 Complete.\n",
      "Top Ingredients: ['Makeup and Beauty Blog | Makeup Reviews, Swatches and How-To Makeup', 'Makeup and Beauty Blog']\n",
      "Reasoning Output: Error during reasoning: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************bt8A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}\n"
     ]
    }
   ],
   "source": [
    "from semantica.kg import CentralityCalculator, CommunityDetector\n",
    "from semantica.reasoning import GraphReasoner\n",
    "from semantica.visualization import KGVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Key Node Analysis\n",
    "centrality = CentralityCalculator().calculate_degree_centrality(kg)\n",
    "rankings = centrality.get(\"rankings\", [])[:3]\n",
    "\n",
    "# 2. Component Analysis\n",
    "communities = CommunityDetector().detect_communities(kg, algorithm=\"louvain\")\n",
    "num_communities = len(communities.get(\"communities\", []))\n",
    "\n",
    "# 3. Advanced Reasoning using Groq\n",
    "reasoner = GraphReasoner(core=core, provider=\"groq\", model=\"llama-3.1-8b-instant\")\n",
    "query = \"What ingredients should be avoided with Retinol based on the graph?\"\n",
    "answer = reasoner.reason(kg, query)\n",
    "\n",
    "# 4. Visualization\n",
    "viz = KGVisualizer()\n",
    "viz.visualize_network(kg, layout=\"spring\", title=\"Skincare Ingredient Intelligence Graph (Groq Enhanced)\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Phase 5 Complete.\")\n",
    "print(f\"Top Ingredients: {[r['node'] for r in rankings]}\")\n",
    "print(f\"Reasoning Output: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
