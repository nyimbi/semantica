{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/use_cases/finance/03_Earnings_Call_Analysis.ipynb)\n",
        "\n",
        "# Earnings Call Transcript Analysis with Docling and Semantica\n",
        "\n",
        "## ðŸ“„ Earnings Call Transcript PDF\n",
        "\n",
        "**Example:** Download a single earnings call transcript PDF from [SEC EDGAR](https://www.sec.gov/edgar/searchedgar/companysearch.html) or company investor relations pages. Use one PDF file for this analysis.\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "Extract insights from earnings call transcripts by building a knowledge graph with entity extraction, relationship mapping, and GraphRAG-powered Q&A.\n",
        "\n",
        "**Workflow:** `PDF â†’ Parse â†’ Extract Entities/Relations â†’ Build KG â†’ GraphRAG â†’ Answers`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "\n",
        "```bash\n",
        "pip install semantica\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Groq LLM provider\n",
        "from semantica.llms import Groq\n",
        "import os\n",
        "\n",
        "groq_llm = Groq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Groq LLM initialized: {groq_llm.model}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Parse PDF with Docling\n",
        "\n",
        "Parse earnings call PDF and extract financial tables using DoclingParser.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Parse PDF with Docling\n",
        "from semantica.parse import DoclingParser\n",
        "\n",
        "parser = DoclingParser(\n",
        "    export_format=\"markdown\",\n",
        "    enable_ocr=False,\n",
        "    table_extraction_mode=\"auto\"\n",
        ")\n",
        "\n",
        "# Example parsed document (replace with actual PDF parsing)\n",
        "parsed_doc = {\n",
        "    \"full_text\": \"\"\"Q1 2024 Earnings Call Transcript\n",
        "\n",
        "Company: TechCorp Inc.\n",
        "Date: January 25, 2024\n",
        "\n",
        "Prepared Remarks:\n",
        "Our revenue for Q1 2024 was $2.5 billion, representing 15% year-over-year growth. \n",
        "EPS was $1.25 per share. We expect Q2 revenue to be between $2.6 and $2.8 billion.\n",
        "\n",
        "Q&A Session:\n",
        "Analyst: What's your guidance for the full year?\n",
        "CEO: We're maintaining our full-year guidance of $10.5 to $11 billion in revenue.\"\"\",\n",
        "    \"tables\": [],\n",
        "    \"metadata\": {\"title\": \"Q1 2024 Earnings Call\"}\n",
        "}\n",
        "\n",
        "print(f\"âœ“ Document parsed: {parsed_doc['metadata'].get('title', 'Unknown')}\")\n",
        "print(f\"  Text length: {len(parsed_doc['full_text'])} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Normalize Text\n",
        "\n",
        "Normalize extracted text using TextNormalizer for consistent processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Normalize text with Semantica\n",
        "from semantica.normalize import TextNormalizer\n",
        "\n",
        "text_normalizer = TextNormalizer()\n",
        "normalized_text = text_normalizer.normalize(\n",
        "    parsed_doc[\"full_text\"],\n",
        "    case=\"lower\",\n",
        "    remove_extra_whitespace=True\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Text normalized: {len(normalized_text)} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Extract Entities\n",
        "\n",
        "Extract entities (organizations, people, financial terms) using NERExtractor with Groq LLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Extract entities using NERExtractor with Groq\n",
        "from semantica.semantic_extract import NERExtractor\n",
        "\n",
        "ner = NERExtractor(\n",
        "    method=\"llm\",\n",
        "    provider=\"groq\",\n",
        "    llm_model=\"llama-3.1-8b-instant\",\n",
        "    min_confidence=0.7\n",
        ")\n",
        "\n",
        "entities = ner.extract_entities(\n",
        "    normalized_text,\n",
        "    entity_types=[\"ORG\", \"PERSON\", \"MONEY\", \"DATE\", \"PERCENT\"]\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Entities extracted: {len(entities)}\")\n",
        "if entities:\n",
        "    print(f\"  Sample: {entities[0].text} ({entities[0].label})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Extract Financial Metrics\n",
        "\n",
        "Extract financial metrics (money, percentages, dates) from text and tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Extract financial metrics using NERExtractor\n",
        "financial_entities = ner.extract_entities(\n",
        "    normalized_text,\n",
        "    entity_types=[\"MONEY\", \"PERCENT\", \"DATE\"]\n",
        ")\n",
        "\n",
        "financial_metrics = {}\n",
        "for entity in financial_entities:\n",
        "    if entity.label == \"MONEY\":\n",
        "        financial_metrics[entity.text] = entity.text\n",
        "\n",
        "print(f\"âœ“ Financial entities: {len(financial_entities)}\")\n",
        "print(f\"  Financial metrics: {len(financial_metrics)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Extract Relationships\n",
        "\n",
        "Extract relationships between entities using RelationExtractor with Groq LLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Extract relationships using RelationExtractor with Groq LLM\n",
        "from semantica.semantic_extract import RelationExtractor\n",
        "\n",
        "relation_extractor = RelationExtractor(\n",
        "    method=\"llm\",\n",
        "    confidence_threshold=0.6,\n",
        "    relation_types=[\"HAS_REVENUE\", \"HAS_EPS\", \"STATES\", \"PROVIDES_GUIDANCE\", \"OPERATES_IN\"]\n",
        ")\n",
        "\n",
        "relationships = relation_extractor.extract_relations(\n",
        "    normalized_text,\n",
        "    entities=entities,\n",
        "    provider=\"groq\",\n",
        "    llm_model=\"llama-3.1-8b-instant\"\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Relationships extracted: {len(relationships)}\")\n",
        "if relationships:\n",
        "    rel = relationships[0]\n",
        "    print(f\"  Sample: {rel.subject.text} â†’ {rel.predicate} â†’ {rel.object.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Extract RDF Triplets\n",
        "\n",
        "Extract RDF triplets (subject-predicate-object) using TripletExtractor with Groq LLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Extract RDF triplets using TripletExtractor with Groq LLM\n",
        "from semantica.semantic_extract import TripletExtractor\n",
        "\n",
        "triplet_extractor = TripletExtractor(\n",
        "    method=\"llm\",\n",
        "    include_temporal=True,\n",
        "    include_provenance=True\n",
        ")\n",
        "\n",
        "triplets = triplet_extractor.extract_triplets(\n",
        "    normalized_text,\n",
        "    entities=entities,\n",
        "    relations=relationships,\n",
        "    provider=\"groq\",\n",
        "    llm_model=\"llama-3.1-8b-instant\"\n",
        ")\n",
        "\n",
        "validated_triplets = triplet_extractor.validate_triplets(triplets)\n",
        "\n",
        "print(f\"âœ“ RDF triplets extracted: {len(triplets)}\")\n",
        "if triplets:\n",
        "    t = triplets[0]\n",
        "    print(f\"  Sample: {t.subject} â†’ {t.predicate} â†’ {t.object}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Detect Conflicts\n",
        "\n",
        "Detect conflicts in extracted entities and relationships using ConflictDetector.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Detect conflicts in extracted entities and relationships\n",
        "from semantica.conflicts import ConflictDetector, SourceTracker, SourceReference\n",
        "\n",
        "source_tracker = SourceTracker()\n",
        "conflict_detector = ConflictDetector(\n",
        "    source_tracker=source_tracker,\n",
        "    confidence_threshold=0.7\n",
        ")\n",
        "\n",
        "# Track sources for entities\n",
        "for entity in entities:\n",
        "    entity_id = getattr(entity, 'id', None) or getattr(entity, 'text', '')\n",
        "    entity_name = getattr(entity, 'text', '')\n",
        "    source_tracker.track_property_source(\n",
        "        entity_id,\n",
        "        'name',\n",
        "        entity_name,\n",
        "        source=SourceReference(\n",
        "            source='earnings_call',\n",
        "            timestamp='2024-Q1',\n",
        "            metadata={'entity_type': getattr(entity, 'label', 'UNKNOWN')}\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Detect value conflicts\n",
        "value_conflicts = conflict_detector.detect_value_conflicts(\n",
        "    [{'id': getattr(e, 'id', ''), 'name': getattr(e, 'text', '')} for e in entities],\n",
        "    property_name='name'\n",
        ")\n",
        "\n",
        "# Detect relationship conflicts\n",
        "relationship_conflicts = conflict_detector.detect_relationship_conflicts(relationships)\n",
        "\n",
        "print(f\"âœ“ Conflicts detected\")\n",
        "print(f\"  Value conflicts: {len(value_conflicts)}\")\n",
        "print(f\"  Relationship conflicts: {len(relationship_conflicts)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Resolve Conflicts\n",
        "\n",
        "Resolve detected conflicts using ConflictResolver with voting strategy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Resolve conflicts using ConflictResolver\n",
        "from semantica.conflicts import ConflictResolver\n",
        "\n",
        "conflict_resolver = ConflictResolver(\n",
        "    default_strategy='voting',\n",
        "    source_tracker=source_tracker\n",
        ")\n",
        "\n",
        "# Resolve value conflicts\n",
        "resolved_entities = list(entities)\n",
        "resolved_conflicts = []\n",
        "for conflict in value_conflicts:\n",
        "    resolution = conflict_resolver.resolve_conflict(conflict, strategy='voting')\n",
        "    resolved_conflicts.append(resolution)\n",
        "\n",
        "# Resolve relationship conflicts\n",
        "resolved_relationships = list(relationships)\n",
        "for conflict in relationship_conflicts:\n",
        "    resolution = conflict_resolver.resolve_conflict(conflict, strategy='voting')\n",
        "    resolved_conflicts.append(resolution)\n",
        "\n",
        "print(f\"âœ“ Conflicts resolved: {len(resolved_conflicts)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Deduplicate Entities\n",
        "\n",
        "Detect and merge duplicate entities using DuplicateDetector and EntityMerger.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 9: Deduplicate entities using DuplicateDetector and EntityMerger\n",
        "from semantica.deduplication import DuplicateDetector, EntityMerger\n",
        "\n",
        "duplicate_detector = DuplicateDetector(\n",
        "    similarity_threshold=0.8,\n",
        "    confidence_threshold=0.7\n",
        ")\n",
        "\n",
        "# Convert entities to dict format\n",
        "entity_dicts = []\n",
        "for entity in resolved_entities:\n",
        "    entity_dicts.append({\n",
        "        'id': getattr(entity, 'id', ''),\n",
        "        'name': getattr(entity, 'text', ''),\n",
        "        'type': getattr(entity, 'label', 'UNKNOWN'),\n",
        "        'confidence': getattr(entity, 'confidence', 1.0),\n",
        "        'metadata': getattr(entity, 'metadata', {})\n",
        "    })\n",
        "\n",
        "# Detect duplicates\n",
        "duplicates = duplicate_detector.detect_duplicates(entity_dicts)\n",
        "\n",
        "# Merge duplicates\n",
        "entity_merger = EntityMerger(preserve_provenance=True)\n",
        "merge_operations = entity_merger.merge_duplicates(\n",
        "    entity_dicts,\n",
        "    strategy='keep_most_complete'\n",
        ")\n",
        "\n",
        "merged_entities = [op.merged_entity for op in merge_operations]\n",
        "\n",
        "print(f\"âœ“ Deduplication complete\")\n",
        "print(f\"  Original entities: {len(entity_dicts)}\")\n",
        "print(f\"  Merged entities: {len(merged_entities)}\")\n",
        "print(f\"  Duplicates removed: {len(entity_dicts) - len(merged_entities)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Build Knowledge Graph\n",
        "\n",
        "Build knowledge graph from cleaned entities, relationships, and triplets using GraphBuilder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 10: Build knowledge graph from cleaned entities, resolved relationships, and triplets\n",
        "from semantica.kg import GraphBuilder\n",
        "\n",
        "graph_builder = GraphBuilder(\n",
        "    merge_entities=True,\n",
        "    entity_resolution_strategy=\"fuzzy\"\n",
        ")\n",
        "\n",
        "# Convert triplets to relationships format\n",
        "triplet_relationships = []\n",
        "for triplet in triplets:\n",
        "    triplet_relationships.append({\n",
        "        \"source\": triplet.subject,\n",
        "        \"predicate\": triplet.predicate,\n",
        "        \"target\": triplet.object,\n",
        "        \"confidence\": triplet.confidence,\n",
        "        \"metadata\": triplet.metadata\n",
        "    })\n",
        "\n",
        "all_relationships = resolved_relationships + triplet_relationships\n",
        "\n",
        "kg_data = {\n",
        "    \"entities\": merged_entities,\n",
        "    \"relationships\": all_relationships,\n",
        "    \"triplets\": triplets,\n",
        "    \"metadata\": {\n",
        "        \"source\": \"earnings_call_transcript\",\n",
        "        \"financial_metrics\": financial_metrics,\n",
        "        \"extraction_method\": \"Groq LLM\"\n",
        "    }\n",
        "}\n",
        "\n",
        "knowledge_graph = graph_builder.build(\n",
        "    sources=[kg_data],\n",
        "    merge_entities=True\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Knowledge graph built\")\n",
        "print(f\"  Entities: {len(knowledge_graph.get('entities', []))}\")\n",
        "print(f\"  Relationships: {len(knowledge_graph.get('relationships', []))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Analyze Knowledge Graph\n",
        "\n",
        "Analyze graph structure using GraphAnalyzer (centrality, communities, connectivity).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 11: Analyze knowledge graph using GraphAnalyzer\n",
        "from semantica.kg import GraphAnalyzer\n",
        "\n",
        "graph_analyzer = GraphAnalyzer()\n",
        "analysis = graph_analyzer.analyze_graph(knowledge_graph)\n",
        "centrality = graph_analyzer.calculate_centrality(knowledge_graph, 'degree')\n",
        "communities = graph_analyzer.detect_communities(knowledge_graph, algorithm='louvain')\n",
        "connectivity = graph_analyzer.analyze_connectivity(knowledge_graph)\n",
        "metrics = graph_analyzer.compute_metrics(knowledge_graph)\n",
        "\n",
        "top_entities = []\n",
        "if centrality and 'rankings' in centrality:\n",
        "    top_entities = centrality['rankings'][:5]\n",
        "\n",
        "num_communities = len(communities.get('communities', [])) if isinstance(communities, dict) else 0\n",
        "\n",
        "print(f\"âœ“ Graph analysis complete\")\n",
        "print(f\"  Communities: {num_communities}\")\n",
        "print(f\"  Top entities: {len(top_entities)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Build Context Graph\n",
        "\n",
        "Build ContextGraph from knowledge graph for enhanced retrieval and GraphRAG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 12: Build context graph for enhanced retrieval\n",
        "from semantica.context import ContextGraph\n",
        "\n",
        "context_graph = ContextGraph(\n",
        "    extract_entities=True,\n",
        "    extract_relationships=True\n",
        ")\n",
        "\n",
        "# Convert knowledge graph to context graph format\n",
        "nodes = []\n",
        "for entity in knowledge_graph.get('entities', []):\n",
        "    nodes.append({\n",
        "        \"id\": entity.get('id', entity.get('name', '')),\n",
        "        \"type\": entity.get('type', 'entity'),\n",
        "        \"properties\": {\n",
        "            \"content\": entity.get('name', ''),\n",
        "            \"confidence\": entity.get('confidence', 1.0),\n",
        "            **entity.get('metadata', {})\n",
        "        }\n",
        "    })\n",
        "\n",
        "edges = []\n",
        "for rel in knowledge_graph.get('relationships', []):\n",
        "    edges.append({\n",
        "        \"source_id\": rel.get('source', ''),\n",
        "        \"target_id\": rel.get('target', ''),\n",
        "        \"type\": rel.get('predicate', 'related_to'),\n",
        "        \"weight\": rel.get('confidence', 1.0)\n",
        "    })\n",
        "\n",
        "node_count = context_graph.add_nodes(nodes)\n",
        "edge_count = context_graph.add_edges(edges)\n",
        "\n",
        "print(f\"âœ“ Context graph built\")\n",
        "print(f\"  Nodes: {node_count}\")\n",
        "print(f\"  Edges: {edge_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Context Retrieval\n",
        "\n",
        "Set up hybrid retrieval (vector + graph) using ContextRetriever for GraphRAG queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 13: Set up hybrid context retrieval and demonstrate GraphRAG\n",
        "from semantica.vector_store import VectorStore\n",
        "from semantica.context import ContextRetriever\n",
        "\n",
        "# Initialize VectorStore\n",
        "vector_store = VectorStore(backend=\"faiss\")\n",
        "vector_store.add(\n",
        "    texts=[parsed_doc[\"full_text\"]],\n",
        "    metadata=[{\"source\": \"earnings_call\", \"type\": \"transcript\"}]\n",
        ")\n",
        "\n",
        "# Initialize ContextRetriever\n",
        "context_retriever = ContextRetriever(\n",
        "    knowledge_graph=context_graph,\n",
        "    vector_store=vector_store,\n",
        "    hybrid_alpha=0.6,\n",
        "    use_graph_expansion=True,\n",
        "    max_expansion_hops=2\n",
        ")\n",
        "\n",
        "# Retrieve context for financial queries\n",
        "financial_queries = [\n",
        "    \"What was the company's revenue guidance?\",\n",
        "    \"What were the key financial metrics discussed?\"\n",
        "]\n",
        "\n",
        "retrieved_contexts = []\n",
        "for query in financial_queries:\n",
        "    results = context_retriever.retrieve(\n",
        "        query=query,\n",
        "        max_results=3,\n",
        "        min_relevance_score=0.2\n",
        "    )\n",
        "    retrieved_contexts.append({\n",
        "        \"query\": query,\n",
        "        \"results\": results,\n",
        "        \"count\": len(results)\n",
        "    })\n",
        "\n",
        "print(f\"âœ“ Hybrid retrieval configured\")\n",
        "print(f\"  Queries processed: {len(retrieved_contexts)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Entity Linking\n",
        "\n",
        "Link entities across sources and assign URIs using EntityLinker.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 14: Link entities using EntityLinker\n",
        "from semantica.context import EntityLinker\n",
        "\n",
        "entity_linker = EntityLinker(knowledge_graph=knowledge_graph)\n",
        "\n",
        "# Assign URIs to key entities\n",
        "linked_entities = []\n",
        "for entity in merged_entities[:10]:\n",
        "    entity_id = entity.get('id', entity.get('name', ''))\n",
        "    entity_name = entity.get('name', '')\n",
        "    entity_type = entity.get('type', 'UNKNOWN')\n",
        "    \n",
        "    uri = entity_linker.assign_uri(\n",
        "        entity_id=entity_id,\n",
        "        text=entity_name,\n",
        "        entity_type=entity_type\n",
        "    )\n",
        "    linked_entities.append({\n",
        "        \"entity_id\": entity_id,\n",
        "        \"name\": entity_name,\n",
        "        \"uri\": uri,\n",
        "        \"type\": entity_type\n",
        "    })\n",
        "\n",
        "# Build entity web\n",
        "entity_web = entity_linker.build_entity_web()\n",
        "\n",
        "print(f\"âœ“ Entity linking complete\")\n",
        "print(f\"  Entities linked: {len(linked_entities)}\")\n",
        "print(f\"  Entity web nodes: {len(entity_web.get('nodes', []))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 15: Agent Memory\n",
        "\n",
        "Store and retrieve memories using AgentMemory with RAG integration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 15: Store and retrieve memories using AgentMemory\n",
        "from semantica.context import AgentMemory\n",
        "\n",
        "agent_memory = AgentMemory(\n",
        "    vector_store=vector_store,\n",
        "    knowledge_graph=knowledge_graph,\n",
        "    retention_days=30\n",
        ")\n",
        "\n",
        "# Store earnings call memories\n",
        "memory_ids = []\n",
        "memory_contents = [\n",
        "    f\"Earnings call transcript: {parsed_doc['metadata'].get('title', 'Q1 2024')}\",\n",
        "    f\"Financial metrics extracted: {len(financial_metrics)} metrics\",\n",
        "    f\"Key entities identified: {len(merged_entities)} entities\"\n",
        "]\n",
        "\n",
        "for content in memory_contents:\n",
        "    memory_id = agent_memory.store(\n",
        "        content=content,\n",
        "        metadata={\"source\": \"earnings_call\", \"type\": \"transcript_analysis\"},\n",
        "        extract_entities=True,\n",
        "        extract_relationships=True\n",
        "    )\n",
        "    memory_ids.append(memory_id)\n",
        "\n",
        "# Retrieve memories\n",
        "financial_memories = agent_memory.retrieve(\n",
        "    query=\"financial metrics and earnings\",\n",
        "    max_results=5\n",
        ")\n",
        "\n",
        "memory_stats = agent_memory.get_statistics()\n",
        "\n",
        "print(f\"âœ“ Agent memory configured\")\n",
        "print(f\"  Memories stored: {len(memory_ids)}\")\n",
        "print(f\"  Total memories: {memory_stats.get('total_memories', 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 16: Agent Context\n",
        "\n",
        "Unified context management with AgentContext (auto-detects RAG vs GraphRAG).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 16: High-level context management with AgentContext\n",
        "from semantica.context import AgentContext\n",
        "\n",
        "agent_context = AgentContext(\n",
        "    vector_store=vector_store,\n",
        "    knowledge_graph=context_graph,\n",
        "    use_graph_expansion=True,\n",
        "    max_expansion_hops=2,\n",
        "    hybrid_alpha=0.6,\n",
        "    retention_days=30\n",
        ")\n",
        "\n",
        "# Store content with auto-extraction\n",
        "memory_id = agent_context.store(\n",
        "    content=parsed_doc[\"full_text\"][:1000],\n",
        "    metadata={\"source\": \"earnings_call\", \"date\": \"2024-Q1\"},\n",
        "    extract_entities=True,\n",
        "    extract_relationships=True,\n",
        "    link_entities=True\n",
        ")\n",
        "\n",
        "# Retrieve with auto-detected GraphRAG\n",
        "graphrag_results = agent_context.retrieve(\n",
        "    query=\"What was discussed about revenue growth?\",\n",
        "    max_results=5,\n",
        "    expand_graph=True,\n",
        "    include_entities=True\n",
        ")\n",
        "\n",
        "context_stats = agent_context.stats()\n",
        "\n",
        "print(f\"âœ“ AgentContext configured\")\n",
        "print(f\"  Memory stored: {memory_id}\")\n",
        "print(f\"  GraphRAG results: {len(graphrag_results)}\")\n",
        "print(f\"  Total memories: {context_stats.get('total_memories', 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 17: Answer Generation\n",
        "\n",
        "Generate answers to financial questions using Groq LLM with retrieved context and knowledge graph.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 18: Export Results\n",
        "\n",
        "Export knowledge graph and analysis results to JSON and RDF formats.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 17: Generate answers using Groq LLM from semantica.llms module\n",
        "financial_questions = [\n",
        "    \"What were the key financial metrics discussed in the earnings call?\",\n",
        "    \"What guidance did management provide for future quarters?\"\n",
        "]\n",
        "\n",
        "generated_answers = []\n",
        "for question in financial_questions:\n",
        "    # Retrieve relevant context\n",
        "    context_results = context_retriever.retrieve(\n",
        "        query=question,\n",
        "        max_results=3,\n",
        "        min_relevance_score=0.2\n",
        "    )\n",
        "    \n",
        "    # Build context from retrieved results\n",
        "    context_text = \"\\n\\n\".join([\n",
        "        f\"Context {i+1}: {result.get('content', result.get('text', ''))}\"\n",
        "        for i, result in enumerate(context_results[:3])\n",
        "    ])\n",
        "    \n",
        "    # Extract relevant entities\n",
        "    relevant_entities = [\n",
        "        entity.get('name', '') for entity in knowledge_graph.get('entities', [])[:10]\n",
        "    ]\n",
        "    entities_text = \", \".join(relevant_entities[:5]) if relevant_entities else \"N/A\"\n",
        "    \n",
        "    # Build prompt\n",
        "    prompt = f\"\"\"Based on the following earnings call transcript context and knowledge graph, answer the question.\n",
        "\n",
        "Context from transcript:\n",
        "{context_text[:1000]}\n",
        "\n",
        "Key entities identified: {entities_text}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Provide a comprehensive answer based on the context provided. If information is not available in the context, state that clearly.\n",
        "\n",
        "Answer:\"\"\"\n",
        "    \n",
        "    # Generate answer using Groq LLM\n",
        "    try:\n",
        "        answer = groq_llm.generate(\n",
        "            prompt,\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        generated_answers.append({\n",
        "            \"question\": question,\n",
        "            \"answer\": answer,\n",
        "            \"context_sources\": len(context_results),\n",
        "            \"model\": groq_llm.model\n",
        "        })\n",
        "    except Exception as e:\n",
        "        generated_answers.append({\n",
        "            \"question\": question,\n",
        "            \"answer\": f\"Error generating answer: {str(e)}\",\n",
        "            \"context_sources\": len(context_results),\n",
        "            \"model\": groq_llm.model\n",
        "        })\n",
        "\n",
        "print(f\"âœ“ Answer generation complete using Groq LLM\")\n",
        "print(f\"  LLM Provider: Groq ({groq_llm.model})\")\n",
        "print(f\"  Questions answered: {len(generated_answers)}\")\n",
        "if generated_answers:\n",
        "    print(f\"  Sample question: '{generated_answers[0]['question']}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 18: Export structured outputs including triplets\n",
        "from semantica.export import JSONExporter, RDFExporter\n",
        "\n",
        "json_exporter = JSONExporter()\n",
        "rdf_exporter = RDFExporter()\n",
        "\n",
        "# Export knowledge graph to JSON\n",
        "kg_json = json_exporter.export(knowledge_graph, format=\"json\")\n",
        "\n",
        "# Export knowledge graph to RDF (Turtle format)\n",
        "rdf_output = rdf_exporter.export_to_rdf(knowledge_graph, format=\"turtle\")\n",
        "\n",
        "# Create analysis summary\n",
        "analysis_summary = {\n",
        "    \"financial_metrics\": financial_metrics,\n",
        "    \"extraction_stats\": {\n",
        "        \"entities\": len(entities),\n",
        "        \"relationships\": len(relationships),\n",
        "        \"triplets\": len(triplets),\n",
        "        \"provider\": f\"Groq LLM (semantica.llms module) - {groq_llm.model}\"\n",
        "    },\n",
        "    \"conflict_resolution\": {\n",
        "        \"conflicts_detected\": len(value_conflicts) + len(relationship_conflicts),\n",
        "        \"conflicts_resolved\": len(resolved_conflicts),\n",
        "        \"strategy\": \"voting\"\n",
        "    },\n",
        "    \"deduplication\": {\n",
        "        \"original_entities\": len(entity_dicts),\n",
        "        \"duplicates_detected\": len(duplicates),\n",
        "        \"merged_entities\": len(merged_entities),\n",
        "        \"strategy\": \"keep_most_complete\"\n",
        "    },\n",
        "    \"knowledge_graph\": {\n",
        "        \"entities\": len(knowledge_graph.get('entities', [])),\n",
        "        \"relationships\": len(knowledge_graph.get('relationships', []))\n",
        "    },\n",
        "    \"graph_analytics\": {\n",
        "        \"metrics\": metrics,\n",
        "        \"communities\": num_communities,\n",
        "        \"top_entities\": top_entities[:5] if top_entities else []\n",
        "    },\n",
        "    \"context_graph\": {\n",
        "        \"nodes\": len(context_graph.nodes),\n",
        "        \"edges\": len(context_graph.edges)\n",
        "    },\n",
        "    \"context_retrieval\": {\n",
        "        \"queries_processed\": len(retrieved_contexts),\n",
        "        \"total_results\": sum(c[\"count\"] for c in retrieved_contexts)\n",
        "    },\n",
        "    \"entity_linking\": {\n",
        "        \"entities_linked\": len(linked_entities),\n",
        "        \"entity_web_nodes\": len(entity_web.get('nodes', [])),\n",
        "        \"entity_web_edges\": len(entity_web.get('edges', []))\n",
        "    },\n",
        "    \"agent_memory\": {\n",
        "        \"memories_stored\": len(memory_ids),\n",
        "        \"total_memories\": memory_stats.get('total_memories', 0)\n",
        "    },\n",
        "    \"agent_context\": {\n",
        "        \"graphrag_results\": len(graphrag_results),\n",
        "        \"total_memories\": context_stats.get('total_memories', 0)\n",
        "    },\n",
        "    \"answer_generation\": {\n",
        "        \"questions_answered\": len(generated_answers),\n",
        "        \"llm_provider\": \"Groq\",\n",
        "        \"llm_model\": groq_llm.model,\n",
        "        \"answers\": [\n",
        "            {\n",
        "                \"question\": ans[\"question\"],\n",
        "                \"answer_length\": len(ans[\"answer\"]),\n",
        "                \"context_sources\": ans[\"context_sources\"]\n",
        "            }\n",
        "            for ans in generated_answers\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"âœ“ Export complete\")\n",
        "print(f\"  Analysis summary: {len(analysis_summary)} sections\")\n",
        "print(f\"  Knowledge graph (JSON): {len(kg_json) if isinstance(kg_json, dict) else 0} items\")\n",
        "print(f\"  RDF (Turtle): {len(rdf_output)} characters\")\n",
        "print(f\"  LLM answers generated: {len(generated_answers)}\")\n",
        "print(f\"  LLM provider: Groq ({groq_llm.model})\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
